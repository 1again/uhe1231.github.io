<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZhiWei Show</title>
  
  <subtitle>Just Show Me</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhiwei.show/"/>
  <updated>2020-05-10T09:47:38.822Z</updated>
  <id>https://zhiwei.show/</id>
  
  <author>
    <name>ZhiWei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>nginx的mirror模块请求返回400状态</title>
    <link href="https://zhiwei.show/2020/05/10/%E5%A4%8D%E7%9B%98/%E9%97%AE%E9%A2%98/nginx%E7%9A%84mirror%E7%AB%99%E7%82%B9%E6%94%B6%E5%88%B0400%E7%9A%84%E7%8A%B6%E6%80%81/"/>
    <id>https://zhiwei.show/2020/05/10/复盘/问题/nginx的mirror站点收到400的状态/</id>
    <published>2020-05-10T01:37:48.000Z</published>
    <updated>2020-05-10T09:47:38.822Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>突然被抓来协助大数据的上报网关(OpenResty)</p><p>client -&gt; OpenResty -&gt; Kafka -&gt; ClickHouse</p><p>这里的OpenResty负责数据的兼容, 过滤, 路由</p><p>因为需要经常的修改OpenResty的逻辑配合数据分析这边的需求<br>导致改动容易出现问题, 需要搞个测试环境.<br>通过测试环境的验证后, 在更新到正式环境</p><p>实施方案是使用nginx的mirror模块将请求镜像到测试站点.<br>同样的代码和配置, 通过环境变量来区分生产和测试环境</p><p>大概是这样的.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">                                (不返回client)</span><br><span class="line">client &lt;-------------&gt; nginx &lt;-------------&gt; mirror</span><br></pre></td></tr></table></figure><p>那么问题来了<br>在实施中, 请求主站点时, 镜像站点也能收到请求<br>但一直显示<code>status_code 400</code>, 从表现上来看像是POST的数据丢失了.<br>在nginx的log_format把<code>$request_body</code>参数加上, 发现确实POST数据没有.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.19.0.1 - [08/May/2020:06:35:09] &quot;POST /user_login HTTP/1.0&quot; 400 419 &quot;-&quot;</span><br><span class="line">172.19.0.1 - [08/May/2020:07:01:09] &quot;POST /user_login HTTP/1.0&quot; 400 419 &quot;-&quot;</span><br><span class="line">172.19.0.1 - [08/May/2020:07:02:43] &quot;POST /user_login HTTP/1.0&quot; 400 419 &quot;-&quot;</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="思路验证"><a href="#思路验证" class="headerlink" title="思路验证"></a>思路验证</h1><h2 id="nginx的配置问题"><a href="#nginx的配置问题" class="headerlink" title="nginx的配置问题?"></a>nginx的配置问题?</h2><p>难道是的配置有问题?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">mirror /mirror;</span><br><span class="line"></span><br><span class="line">location /mirror &#123;</span><br><span class="line">    internal;</span><br><span class="line">    proxy_pass http://127.0.0.1:8080$request_uri;</span><br><span class="line">    proxy_set_header X-Original-URI $request_uri;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>主站点上日志的POST数据是没问题的, 所以很容易怀疑是mirror配置的问题</p><p>查看nginx的官网发现<code>mirror_request_body</code>是用于控制镜像请求时是否附带body数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Syntax:mirror_request_body on | off;</span><br><span class="line">Default:</span><br><span class="line">mirror_request_body on;</span><br><span class="line">Context:http, server, location</span><br></pre></td></tr></table></figure><p>但这个参数默认是打开的, 所以不是这个问题.</p><h2 id="OpenResty的版本问题"><a href="#OpenResty的版本问题" class="headerlink" title="OpenResty的版本问题?"></a>OpenResty的版本问题?</h2><p>因为使用的docker来搭建的开发环境<br>并且长时间没有更新, 所以怀疑是不是版本兼容问题.<br>使用<code>docker pull OpenResty/OpenResty</code>更新后发现…<br>也不是这个问题</p><h2 id="业务配置的问题"><a href="#业务配置的问题" class="headerlink" title="业务配置的问题?"></a>业务配置的问题?</h2><p>现在无法确定是主站点上的配置问题, 还是镜像站点上配置的问题.<br>所以使用nginx镜像配置了个干净的环境来进行测试.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">server &#123;</span><br><span class="line">    listen 8080 ssl http2</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        return 200;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>结果还是一样, 那么镜像站点的配置问题排除.</p><p>同样的使用nginx配置一个干净的主站点环境, 测试…<br>结果还是一样…</p><h2 id="抓包确认"><a href="#抓包确认" class="headerlink" title="抓包确认"></a>抓包确认</h2><p>当时就纳闷了, 既然请求通过mirror模块发起请求都会出现问题.<br>那就确定了一下, 到底发出来的请求数据有没有问题.</p><p>先将mirror的地址改成本机(本地开发环境), 然后开启<code>Wireshark</code>抓包</p><p><img src="2020-05-10-11-02-01.png" alt></p><p>这么看来mirror模块的请求的POST数据是没问题的.</p><h2 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h2><p>现在我们知道了, 请求的数据是没问题的<br>但是通过mirror模块请求的status_code有问题<br>那就直接请求测试站点看看…</p><p>结果真相来了.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;400 The plain HTTP request was sent to HTTPS port&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;</span><br><span class="line">&lt;h1&gt;400 Bad Request&lt;/h1&gt;</span><br><span class="line">&lt;/center&gt;</span><br><span class="line">&lt;center&gt;The plain HTTP request was sent to HTTPS port&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;</span><br><span class="line">&lt;center&gt;OpenResty/1.15.8.3&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>镜像站点的配置和主站点是一致的, 都是基于ssl的.<br>而主站点里的mirror模块使用的是<code>proxy_pass http://127.0.0.1:8080$request_uri;</code></p><p>至此问题定位完毕, 修复起来也就很简单了.</p><h1 id="结果总结"><a href="#结果总结" class="headerlink" title="结果总结"></a>结果总结</h1><h2 id="细节问题"><a href="#细节问题" class="headerlink" title="细节问题"></a>细节问题</h2><p>配置文件是直接复制的, 所以没有注意到细节.</p><h2 id="对http-status-code理解不深刻"><a href="#对http-status-code理解不深刻" class="headerlink" title="对http status_code理解不深刻"></a>对http status_code理解不深刻</h2><p>之前工作中一直碰到的400都是缺少参数导致服务器处理不了</p><p>其实真正的意思是说client的请求错误, 不仅仅是参数, 经验主义啊.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">6.5.1.  400 Bad Request</span><br><span class="line"></span><br><span class="line">   The 400 (Bad Request) status code indicates that the server cannot or</span><br><span class="line">   will not process the request due to something that is perceived to be</span><br><span class="line">   a client error (e.g., malformed request syntax, invalid request</span><br><span class="line">   message framing, or deceptive request routing).</span><br></pre></td></tr></table></figure><h2 id="从设计上来看"><a href="#从设计上来看" class="headerlink" title="从设计上来看"></a>从设计上来看</h2><p>为什么设计上不将http请求https的错误作为一个独立的status_code<br>猜测可能是因为将错误信息输出在了respone text里<br>所以就没有必要将单独作为一个status_code, 毕竟这种情况也不常见.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h1&gt;&lt;p&gt;突然被抓来协助大数据的上报网关(OpenResty)&lt;/p&gt;
&lt;p&gt;client -&amp;gt; OpenResty -&amp;gt; Kafka -&amp;gt; ClickHouse&lt;/p&gt;
&lt;p&gt;这里的OpenResty负责数据的兼容, 过滤, 路由&lt;/p&gt;
&lt;p&gt;因为需要经常的修改OpenResty的逻辑配合数据分析这边的需求&lt;br&gt;导致改动容易出现问题, 需要搞个测试环境.&lt;br&gt;通过测试环境的验证后, 在更新到正式环境&lt;/p&gt;
&lt;p&gt;实施方案是使用nginx的mirror模块将请求镜像到测试站点.&lt;br&gt;同样的代码和配置, 通过环境变量来区分生产和测试环境&lt;/p&gt;
&lt;p&gt;大概是这样的.&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;                                (不返回client)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;client &amp;lt;-------------&amp;gt; nginx &amp;lt;-------------&amp;gt; mirror&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;那么问题来了&lt;br&gt;在实施中, 请求主站点时, 镜像站点也能收到请求&lt;br&gt;但一直显示&lt;code&gt;status_code 400&lt;/code&gt;, 从表现上来看像是POST的数据丢失了.&lt;br&gt;在nginx的log_format把&lt;code&gt;$request_body&lt;/code&gt;参数加上, 发现确实POST数据没有.&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;172.19.0.1 - [08/May/2020:06:35:09] &amp;quot;POST /user_login HTTP/1.0&amp;quot; 400 419 &amp;quot;-&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.19.0.1 - [08/May/2020:07:01:09] &amp;quot;POST /user_login HTTP/1.0&amp;quot; 400 419 &amp;quot;-&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;172.19.0.1 - [08/May/2020:07:02:43] &amp;quot;POST /user_login HTTP/1.0&amp;quot; 400 419 &amp;quot;-&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="复盘" scheme="https://zhiwei.show/categories/%E5%A4%8D%E7%9B%98/"/>
    
      <category term="问题" scheme="https://zhiwei.show/categories/%E5%A4%8D%E7%9B%98/%E9%97%AE%E9%A2%98/"/>
    
    
      <category term="Ops" scheme="https://zhiwei.show/tags/Ops/"/>
    
      <category term="nginx" scheme="https://zhiwei.show/tags/nginx/"/>
    
      <category term="问题" scheme="https://zhiwei.show/tags/%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>业务的自动化部署</title>
    <link href="https://zhiwei.show/2020/05/04/Ops/%E8%87%AA%E5%8A%A8%E5%8C%96/%E4%B8%9A%E5%8A%A1%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"/>
    <id>https://zhiwei.show/2020/05/04/Ops/自动化/业务的自动化部署/</id>
    <published>2020-05-04T07:04:19.497Z</published>
    <updated>2020-05-10T01:40:05.659Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>游戏行业的滚服需求, 服务之间相互独立<br>每天有大量的服务部署需求<br>并且在保证<code>稳定</code>的前提下尽可能的提高<code>资源利用率</code></p><p>而且还有个问题, 我们没有购买主机的权限<br>需要先由我们下订单, 然后通过邮件通知合作方完成订单的支付<br>这就导致需要预留一定数量的主机, 避免支付响应不及时引发的运营事故</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>我们这里解决问题的是如何实现自动部署<br>可能一些老司机说, 自动部署嘛, 这还不简单<br>写个页面, 然后调用Ansible一下子就完成了.</p><p>但是我们想要做的是完全自动化<br>整个流程无人介入(不出问题的情况下)</p><p>PS: 只是部署, 不负责发布上线</p><a id="more"></a><h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><p>有图有状况…</p><h2 id="功能图"><a href="#功能图" class="headerlink" title="功能图"></a>功能图</h2><p><img src="2020-05-04-15-06-45.png" alt></p><h3 id="新主机自动注册"><a href="#新主机自动注册" class="headerlink" title="新主机自动注册"></a>新主机自动注册</h3><p>使用SaltStack实现主机的注册<br>当新云主机启动时会自动连上Salt-Master<br>进行初始化以及将云主机信息注册到CMDB</p><h3 id="部署检测和调度"><a href="#部署检测和调度" class="headerlink" title="部署检测和调度"></a>部署检测和调度</h3><p>使用Crontab每10分钟检测一次(确实Low, 但是香)<br>如果未使用服务数量不足<br>则根据资源历史使用情况进行筛选部署的主机</p><h3 id="任务执行和查看"><a href="#任务执行和查看" class="headerlink" title="任务执行和查看"></a>任务执行和查看</h3><p>确定了部署的主机后, 通过HTTP请求新建一个部署任务<br>任务系统负责将需要执行的任务转化为SaltStack的State<br>SaltStack将执行完成后的结果保存进Mongodb以便查看</p><h3 id="新主机购买通知"><a href="#新主机购买通知" class="headerlink" title="新主机购买通知"></a>新主机购买通知</h3><p>又是Crontab, 我们基本上一天购买一批主机<br>在固定的时间点, 检测服务部署的失败次数(没有低负载的机器)<br>然后根据失败的服务数量大致的判断需要购买多少主机<br>最后通过API接口下订单, 发邮件通知合作方</p><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p>因为我们整体的规模不是很大<br>所有架构方面做的很简单(维护成本低)</p><p><img src="2020-05-04-17-22-10.png" alt></p><h3 id="基础数据层"><a href="#基础数据层" class="headerlink" title="基础数据层"></a>基础数据层</h3><p>所有的资源和服务的状态<br>OLD-CMDB是历史包袱, 研发用于更新和维护的数据<br>Canal, Kafka是用于实时同步服务的状态(是否上线)<br>CMDB基于HTTP接口为其他系统提供数据支持</p><p>CMDB就应该是干干净净的<code>配置管理数据库</code><br>其他业务逻辑应该在上层封装避免数据和逻辑的耦合</p><h3 id="业务逻辑层"><a href="#业务逻辑层" class="headerlink" title="业务逻辑层"></a>业务逻辑层</h3><p>封装所有的业务逻辑和任务执行所需要的数据, 所有的业务逻辑都在这层体现<br>Approval是为了与办公通信软件进行交互的, 我们这里使用DingTalk来走流程.<br>(走流程的目的是同步信息避免干完事后发现关键人员毫不知情)</p><h3 id="任务执行层"><a href="#任务执行层" class="headerlink" title="任务执行层"></a>任务执行层</h3><p>在SaltStack上封装一层任务系统<br>用来解耦任务状态以及记录任务的执行的数据<br>这里的SaltStack也可以替换成Ansible, Puppet<br>任务执行过程中如果进行干预还没有一个较好的方案<br>一个思路是通过SaltStack的Event来实现(耦合了)</p><h3 id="资源监控层"><a href="#资源监控层" class="headerlink" title="资源监控层"></a>资源监控层</h3><p>监控主机和服务的资源使用情况<br>同样提供统一的接口给外部使用<br>这里为什么使用了三个不同的监控系统<br>Zabbix之前的监控, 所以不想改动, 但是性能已经不能满足需求了<br>OpenFalcon是专为自动化而搭建的监控系统, 设计的JSON格式非常灵活, 但存储和接口不太好用<br>Prometheus只是进行尝试, PromSql很灵活, 性能优秀, 但可扩展性比较复杂, 更像是一个组件</p><h1 id="实施"><a href="#实施" class="headerlink" title="实施"></a>实施</h1><h2 id="部署检测和调度-1"><a href="#部署检测和调度-1" class="headerlink" title="部署检测和调度"></a>部署检测和调度</h2><h3 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h3><p>上面也提到了, 我们使用Crontab定时检测部署的服务是否够用<br>这里有个问题需要解决, 到底预留多少个空闲的服务呢?<br>有些平台开服很快, 一天10个服还不够.<br>有些平台开服龟速, 一星期开不到1个服.<br>写个常量肯定是不行的, 自己骗自己.</p><p>要不通过配置的方式人工的去调整…<br>一开始确实是这么想的, 先搞起来后面在优化.<br>但有同事表示完全没有人会去主动的做调整.</p><p>最后我们决定通过每个平台的最近开服数来动态判断.<br>这个方案可以是可以, 缺点就是自动部署就依赖了外部的系统.<br>导致扩展性和兼容性很差, 尤其是跨部门的情况下.<br>容易出现对方要改, 我们崩溃, 我们要改, 对方不理.<br>也没更好的办法了, 先这么搞吧…</p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><p>这块是个重点, 详细说起来有点像王大妈的裹脚布<br>简单概括一下, 是这么个思路</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">占用资源最大的服务 = 获取最近上线占用资源最大的服务()</span><br><span class="line"></span><br><span class="line">最低负载的比例 = 70%</span><br><span class="line">for 机器 in 所有机器</span><br><span class="line">    # 需要考虑已经部署, 但是没有上线服务的负载情况</span><br><span class="line">    # 这里懒得写的, 不然就很长很臭了...</span><br><span class="line">    机器负载 = 获取机器负载(机器)</span><br><span class="line"></span><br><span class="line">    机器预估负载 = 机器负载 + 占用资源最大的服务</span><br><span class="line">    机器预估负载比例 = 机器预估负载 / 机器的总内存</span><br><span class="line"></span><br><span class="line">    if 机器预估负载比例 &lt; 最低负载的比例</span><br><span class="line">        最低负载的比例 = 机器预估负载比例</span><br><span class="line">        最低负载的机器 = 机器</span><br></pre></td></tr></table></figure><p>然后就能找到了最低负载的机器<br>如果没有的话, 就终止任务, 等待下个检测周期<br>牛奶和机器总会有的…</p><h2 id="任务执行和查看-1"><a href="#任务执行和查看-1" class="headerlink" title="任务执行和查看"></a>任务执行和查看</h2><p>在任务系统将任务的信息转化为SaltStack的State<br>然后通过SaltStack的API去执行<br>最后将执行的结果保存在Mongodb中.</p><p>同时用Crontab每分钟跑一个定时脚本<br>找到<code>执行超时</code>的和<code>执行失败</code>的任务并发送报警通知<br>收到报警时, 我们可以查看任务执行时的详细情况来解决隐患</p><p><img src="2020-05-04-22-38-49.png" alt></p><h2 id="新主机购买通知-1"><a href="#新主机购买通知-1" class="headerlink" title="新主机购买通知"></a>新主机购买通知</h2><p>先来想想, 什么时候需要购买新的主机.<br>在当部署服务时找不低负载主机, 肯定不能触发购买行为<br>因为, 每次找不到低负载主机就触发, 结果就是一天购买十几次的主机<br>(我们没权限直接购买支付, 只能下单, 由合作方支付, 非常高的协作成本和时间成本)</p><p>这时候就要将服务状态修改成<code>等待资源</code>状态.<br>这个状态是为了让购买主机的程序知道, 到底需要购买多少个主机<br>等待购买主机的任务检测时进行下单并且通知合作方</p><p>即使是服务状态已经是<code>等待资源</code>了, 在部署的流程里依然需要进行尝试部署<br>因为不能说上一次没有部署成功, 这一次就不能部署成功<br>资源的使用情况是会随时改变的.</p><h2 id="新主机自动注册-1"><a href="#新主机自动注册-1" class="headerlink" title="新主机自动注册"></a>新主机自动注册</h2><p>我们在购买云主机的时候, 会使用事先制作好的镜像.<br>将Salt-Minion装在镜像里, 启动时会自动的连上Salt-Master<br>进行初始化以及注册到CMDB上</p><p>这里有个问题是用什么来作为主机的唯一标识.<br>实例ID? 主机名? 内网IP? 公网IP? 还是自定义?<br>实例ID或许是个好主意, 但是有些奇奇怪怪的问题.<br>比如不同公有云的实例ID是否会冲突<br>又比如如果我们使用私有云或者没有实例ID的公有云怎么办.</p><p>主机名也有些同样的问题, 主机名是否会冲突<br>如果修改了主机名这个主机还是这个主机吗?</p><p>内网IP, 这个不用想肯定会冲突.</p><p>公网IP又会有没有公网IP的主机情况或者是NAT模式的情况.</p><p>云厂商+区域+实例ID是一个比较好的方案.<br>但是我们用的是 云厂商配置名(云厂商+区域)+内网IP<br>这种方式, 主要是因为, 当时我们没有找到在主机内获取主机实例ID的方式<br>其次云厂商配置名+内网IP的方案会更加的通用.</p><h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>全都自动了, 能有啥好看的…</p><p><img src="2020-05-05-10-01-14.png" alt></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总的来说效率不错.<br>解放了人力, 并且保证了质量和效率.<br>期间也修修补补了很多次(调参)</p><p>在兼容性和扩展性的还不是很满意<br>这个涉及到运维基础的标准和项目的不同需求.<br>很难做到一套通用, 只能将通用的部署抽出来.<br>不同的细节通过脚本来定制化.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;游戏行业的滚服需求, 服务之间相互独立&lt;br&gt;每天有大量的服务部署需求&lt;br&gt;并且在保证&lt;code&gt;稳定&lt;/code&gt;的前提下尽可能的提高&lt;code&gt;资源利用率&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而且还有个问题, 我们没有购买主机的权限&lt;br&gt;需要先由我们下订单, 然后通过邮件通知合作方完成订单的支付&lt;br&gt;这就导致需要预留一定数量的主机, 避免支付响应不及时引发的运营事故&lt;/p&gt;
&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;p&gt;我们这里解决问题的是如何实现自动部署&lt;br&gt;可能一些老司机说, 自动部署嘛, 这还不简单&lt;br&gt;写个页面, 然后调用Ansible一下子就完成了.&lt;/p&gt;
&lt;p&gt;但是我们想要做的是完全自动化&lt;br&gt;整个流程无人介入(不出问题的情况下)&lt;/p&gt;
&lt;p&gt;PS: 只是部署, 不负责发布上线&lt;/p&gt;
    
    </summary>
    
      <category term="Ops" scheme="https://zhiwei.show/categories/Ops/"/>
    
      <category term="自动化" scheme="https://zhiwei.show/categories/Ops/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    
      <category term="Ops" scheme="https://zhiwei.show/tags/Ops/"/>
    
      <category term="自动化" scheme="https://zhiwei.show/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
      <category term="效率" scheme="https://zhiwei.show/tags/%E6%95%88%E7%8E%87/"/>
    
      <category term="SaltStack" scheme="https://zhiwei.show/tags/SaltStack/"/>
    
      <category term="OpenFalcon" scheme="https://zhiwei.show/tags/OpenFalcon/"/>
    
  </entry>
  
  <entry>
    <title>客户端业务异常上报监控</title>
    <link href="https://zhiwei.show/2020/05/03/Ops/%E7%9B%91%E6%8E%A7/%E4%B8%9A%E5%8A%A1%E7%9B%91%E6%8E%A7/%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%9A%E5%8A%A1%E5%BC%82%E5%B8%B8%E4%B8%8A%E6%8A%A5%E7%9B%91%E6%8E%A7/"/>
    <id>https://zhiwei.show/2020/05/03/Ops/监控/业务监控/客户端业务异常上报监控/</id>
    <published>2020-05-03T04:09:00.000Z</published>
    <updated>2020-05-05T08:57:18.098Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我们是一家H5的游戏公司<br>客户端以网页, 小程序, APP的方式发布<br>对CDN的请求非常的大, 所以CDN请求的影响是非常大的.</p><h1 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h1><p>其实一开始是想放在 <a href="/2020/05/02/服务端业务异常日志监控/">服务端业务异常日志监控</a> 一起讲的<br>然而因为这里有一些情况不太一样, 细讲起来差异还挺大的.<br>所以这里就拆开单独写了(真的不是为了凑数!!!)</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li>客户端请求CDN卡顿</li><li>客户端请求服务端卡顿</li><li>客户端代码异常</li></ol><h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><p>elasticsearch, 存储检索<br>logstash, 上报格式转换<br>kibana, 统计展示<br>openresty, 上报网关<br>(和”隔壁”的架构差不多, 只是用openresty替代了filebeat)</p><p>看图…<br><a id="more"></a></p><p><img src="2020-05-03-12-42-55.png" alt="客户端异常上报架构图"></p><p>这里之所以没有使用kafka还是因为量级的原因, 并且logstash自带本地持久化</p><ol><li>对于数据的并发性没有高要求</li><li>对于数据的可靠性没有高要求</li></ol><p>我们是这么考虑的</p><ol><li>目前云主机宕机已经很少了</li><li>而且恰好在宕机的时候把硬盘也搞坏了</li><li>而且恰好硬盘里还存留着没有发送的数据</li><li>最后云主机磁盘的RAID也跟着坏了.</li></ol><p>即使这些情况都发生了, 最多就是丢失一些上报数据, 完全不响应大局<br>综上所述, 我们没有上kafka避免增加维护成本.</p><h1 id="实施"><a href="#实施" class="headerlink" title="实施"></a>实施</h1><h2 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h2><p>ELK老生常谈了, 在我们这个数量级的情况下大同小异<br>没什么特殊的地方, 想看请 <a href="/2020/05/02/服务端业务异常日志监控#实施">出门左转</a></p><h2 id="openresty"><a href="#openresty" class="headerlink" title="openresty"></a>openresty</h2><p>openresty这块, 特意去翻了翻代码<br>发现也没什么好说的, 就是收到请求后<br>使用resty.http模块向logstash发送请求</p><p>唯一有点需要注意的是, 我们使用使用json格式传输<br>为了不影响用户的体验, 发生事件后, 将事件数据push进一个数组<br>然后间隔一分钟将整个数组上报<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        消息1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        消息2</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>哦哦哦, 对了, 还有一点需要注意.<br>因为面向的是多项目的, 所以可能存在不同版本兼容的问题.<br>可以根据项目对数据格式做解析, 也可以定义版本, 根据版本做解析.<br>这里是根据项目对解析的, 大概是这么个流程</p><p>客户端 -&gt; 网关入口 -&gt; 项目解析 -&gt; 标准格式 -&gt; 请求logstash</p><h2 id="埋点"><a href="#埋点" class="headerlink" title="埋点"></a>埋点</h2><p>重点来了, 重点来了, 重点来了<br>这里最难的点在于需要和不同项目组的人<code>沟通</code>.</p><ol><li>得先让和他们解释做这个能带来什么<code>帮助</code></li><li>按照文档标准沟通清楚执行并且最后<code>验收</code></li><li>考虑不同项目的情况是否能够<code>实现</code></li></ol><p>先来看看我们是怎么落地的</p><h3 id="CDN请求超时"><a href="#CDN请求超时" class="headerlink" title="CDN请求超时"></a>CDN请求超时</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在http请求开始时记录开始时间.</span><br><span class="line">在http请求响应时记录结束时间.</span><br><span class="line"></span><br><span class="line">请求耗时 = 结束时间 - 开始时间</span><br><span class="line"></span><br><span class="line">if 请求耗时 &gt; 5秒 then</span><br><span class="line">    触发CDN请求超时事件</span><br><span class="line">    (记录耗时时间, 账号ID, 请求资源名等...)</span><br></pre></td></tr></table></figure><h3 id="CDN请求失败"><a href="#CDN请求失败" class="headerlink" title="CDN请求失败"></a>CDN请求失败</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">当请求HTTP失败时</span><br><span class="line">    触发CDN请求失败事件</span><br><span class="line">    (记录耗时时间, 账号ID, 错误类型, 请求资源名等...)</span><br></pre></td></tr></table></figure><h3 id="请求服务端异常"><a href="#请求服务端异常" class="headerlink" title="请求服务端异常"></a>请求服务端异常</h3><p>这里和CDN请求有些类似, 就不重复了.<br>区别在于, 这个是用于检测用户连接服务器的状态.<br>可能存在服务端系统问题, 服务端代码问题, 服务端网络问题</p><p>同时这个上报也是需要区分项目的<br>如果项目的消息协议是一来一回的, 比如这样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">client ----&gt; client_request_login ----&gt; server</span><br><span class="line">server ----&gt; client_request_login_return ----&gt; client</span><br></pre></td></tr></table></figure></p><p>那这个事情就很好办了, 因为客户端知道收到消息和发送消息如何对应</p><p>如果项目的消息协议是一来多回的, 比如这样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">client ----&gt; client_request_login ----&gt; server</span><br><span class="line">server ----&gt; update_user_coin ----&gt; client</span><br><span class="line">server ----&gt; update_user_info ----&gt; client</span><br><span class="line">server ----&gt; update_user_friends ----&gt; client</span><br></pre></td></tr></table></figure></p><p>那就没戏, 因为没法知道收到的消息对应哪条发送的消息, 也就没法判断了.</p><p>有个办法, 在协议上添加一个字段用于请求表示<br>发送协议时和返回协议时都有对应的请求标识<br>但是这样改造的成本较高, 而且项目方不一定愿意配合修改<br>因为投入收益比太低, 所以这一块不太好落地</p><h3 id="客户端代码异常"><a href="#客户端代码异常" class="headerlink" title="客户端代码异常"></a>客户端代码异常</h3><p>这个其实也很简单, 当客户端代码执行异常时.<br>触发一个异常事件, 等待下次一起上报.</p><p>有个重点是对上报的异常信息要做<code>错误位置</code>截取<br>这是为了方便统计同一个错误总共发生了多少次<br>从而优先解决出现率高的异常错误</p><p>我们使用logstash的grok实现的, 虽然效率不高, 但也能满足我们的需求</p><p>举个例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TypeError: Cannot read property &apos;itemConfig&apos; of null</span><br><span class="line">    at e.IsHas_37TypeItem (https://www.baidu.com/gres/g6/rel/1100/main_6_1100.min.js:2:7760)</span><br><span class="line">    at e.doUpDataItem (https://www.baidu.com/gres/g6/rel/1100/main_6_1100.min.js:2:7140)</span><br><span class="line">    at Function.t.HandlerType (https://www.baidu.com/gres/g6/rel/1100/main_6_1100.min.js:33:14188)</span><br><span class="line">    at Function.e.Dispatch (https://www.baidu.com/gres/g6/rel/1100/main_6_1100.min.js:13:14669)</span><br><span class="line">    at t.UpdateDispatch (https://www.baidu.com/gres/g6/rel/1100/main_6_1100.min.js:222:15347)</span><br><span class="line">    at i.update (https://www.baidu.com/gres/g6/res/start_res/991/merged1.js:4:9583)</span><br><span class="line">    at t (https://www.baidu.com/gres/g6/res/start_res/991/merged1.js:10:11261)</span><br></pre></td></tr></table></figure></p><p>像上面的报错信息, 我们需要截取<code>main_6_1100.min.js:2:7760</code>来作为错误位置来进行聚合统计<br>可以使用下面这个grok的表达式来捕获这个错误位置的信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">grok &#123;</span><br><span class="line">    match =&gt; &#123;</span><br><span class="line">        &quot;message&quot; =&gt; [</span><br><span class="line">            &quot;^.+?(?&lt;fileline&gt;[\w\.]+\.js:[0-9]+:[0-9]+).+$&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就会在上报的数据中添加了一个fileline字段来代表异常错误的位置信息.</p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p><a href="/2020/05/02/服务端业务异常日志监控#监控检测">出门左转</a></p><h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><h2 id="请求CDN监控效果"><a href="#请求CDN监控效果" class="headerlink" title="请求CDN监控效果"></a>请求CDN监控效果</h2><p><img src="2020-05-03-16-19-09.png" alt><br><img src="2020-05-03-16-19-42.png" alt></p><h2 id="请求服务端监控效果"><a href="#请求服务端监控效果" class="headerlink" title="请求服务端监控效果"></a>请求服务端监控效果</h2><p><img src="2020-05-03-16-20-16.png" alt><br><img src="2020-05-03-16-20-44.png" alt></p><p>这里解释下, 为什么上图请求服务端的失败统计表为空.<br>是因为请求服务端失败时记录协议ID实现的<code>成本较高</code><br>而根据协议ID统计出的信息也不具备<code>指导性意见</code></p><p>所以我们就没有纠结这个问题了</p><h2 id="客户端代码异常监控效果"><a href="#客户端代码异常监控效果" class="headerlink" title="客户端代码异常监控效果"></a>客户端代码异常监控效果</h2><p><img src="2020-05-03-16-21-11.png" alt></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>就在写这个Blog的同时, 我们业务的CDN发生了一次故障.</p><p><img src="2020-05-03-17-34-30.png" alt></p><p><img src="2020-05-03-17-43-44.png" alt></p><p>然而我们并没有做相应的监控, 导致响应不及时(主要是没时间精力)<br>由此可见这块监控效果如何, 如果我们能及时的监控报警<br>那么整个团队面对问题的响应速度会非常的块, 从而提升我们产品的质量</p><p>说了好的, 总要说说坏的.</p><ol><li>只能被动的发现问题, 但我们的目标是没有蛀牙</li><li>根据项目的不同, 难以实现统一标准, 维护成本过高</li><li>监控的覆盖率较低, 只能发现重大问题, 对于平时的运营帮助较小</li></ol><p>以上</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;我们是一家H5的游戏公司&lt;br&gt;客户端以网页, 小程序, APP的方式发布&lt;br&gt;对CDN的请求非常的大, 所以CDN请求的影响是非常大的.&lt;/p&gt;
&lt;h1 id=&quot;前提&quot;&gt;&lt;a href=&quot;#前提&quot; class=&quot;headerlink&quot; title=&quot;前提&quot;&gt;&lt;/a&gt;前提&lt;/h1&gt;&lt;p&gt;其实一开始是想放在 &lt;a href=&quot;/2020/05/02/服务端业务异常日志监控/&quot;&gt;服务端业务异常日志监控&lt;/a&gt; 一起讲的&lt;br&gt;然而因为这里有一些情况不太一样, 细讲起来差异还挺大的.&lt;br&gt;所以这里就拆开单独写了(真的不是为了凑数!!!)&lt;/p&gt;
&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;客户端请求CDN卡顿&lt;/li&gt;
&lt;li&gt;客户端请求服务端卡顿&lt;/li&gt;
&lt;li&gt;客户端代码异常&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;方案&quot;&gt;&lt;a href=&quot;#方案&quot; class=&quot;headerlink&quot; title=&quot;方案&quot;&gt;&lt;/a&gt;方案&lt;/h1&gt;&lt;p&gt;elasticsearch, 存储检索&lt;br&gt;logstash, 上报格式转换&lt;br&gt;kibana, 统计展示&lt;br&gt;openresty, 上报网关&lt;br&gt;(和”隔壁”的架构差不多, 只是用openresty替代了filebeat)&lt;/p&gt;
&lt;p&gt;看图…&lt;br&gt;
    
    </summary>
    
      <category term="Ops" scheme="https://zhiwei.show/categories/Ops/"/>
    
      <category term="监控" scheme="https://zhiwei.show/categories/Ops/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="业务监控" scheme="https://zhiwei.show/categories/Ops/%E7%9B%91%E6%8E%A7/%E4%B8%9A%E5%8A%A1%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="Ops" scheme="https://zhiwei.show/tags/Ops/"/>
    
      <category term="监控" scheme="https://zhiwei.show/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="ELK" scheme="https://zhiwei.show/tags/ELK/"/>
    
      <category term="OpenResty" scheme="https://zhiwei.show/tags/OpenResty/"/>
    
  </entry>
  
  <entry>
    <title>服务端业务异常日志监控</title>
    <link href="https://zhiwei.show/2020/05/02/Ops/%E7%9B%91%E6%8E%A7/%E4%B8%9A%E5%8A%A1%E7%9B%91%E6%8E%A7/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%9A%E5%8A%A1%E5%BC%82%E5%B8%B8%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7/"/>
    <id>https://zhiwei.show/2020/05/02/Ops/监控/业务监控/服务端业务异常日志监控/</id>
    <published>2020-05-02T01:03:28.000Z</published>
    <updated>2020-05-05T08:57:44.286Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我们是一家H5的游戏公司<br>多数项目的服务端使用SKYNET+LUA的形式开发<br>协议层走的的websocket</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">一般情况下我们都是走这样的流程</span><br><span class="line"></span><br><span class="line">1. 业务更新版本</span><br><span class="line">2. 等待用户反馈问题</span><br><span class="line">3. 判断客户端还是服务端</span><br><span class="line">4. 根据用户信息查看日志</span><br><span class="line">5. 修复BUG更新版本</span><br><span class="line"></span><br><span class="line">解决问题被动而且效率低下.</span><br><span class="line">大量体验不好的用户直接流失.</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><p>我们采用目前主流的ELK方案来解决这个问题</p><p>使用elasticsearch在日志存储<br>使用logstash做日志标准化<br>使用kibana做统计展示</p><p>另外<br>使用filebeat来做日志收集<br>使用使用Crontab, Python在实现日志监控<br>使用DingTalk接受告警信息</p><p>使用ELK是因为主流, 坑少, 资料多(不喜欢java, 太笨重)<br>使用filebeat是因为原配, 小三的不要(漂亮的还是可以考虑的)<br>使用Crontab, Python是因为es的watch不能满足我们(需求第一)<br>使用DingTalk就要问老板了(老板第一)</p><p>没有使用Kafka是因为没有数据级和可靠性的需求<br>即使后面有了需求, 加入Kafka也不是多大的事</p><p>看图…</p><p><img src="2020-05-02-21-55-00.png" alt></p><h1 id="实施"><a href="#实施" class="headerlink" title="实施"></a>实施</h1><h2 id="filebeat"><a href="#filebeat" class="headerlink" title="filebeat"></a>filebeat</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1. 使用Saltstack部署filebeat并且以后主机上线后会自动部署</span><br><span class="line">    新上线的主机在镜像中已经安装了salt-minion</span><br><span class="line">    启动后会自动连上salt-master然后获取自己应该执行的任务</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2. 使用include_lines选项来包括需要监控的关键字</span><br><span class="line">    我们的日志量很多, 又想节约成本, 所以只传输我们关心的日志.</span><br><span class="line"></span><br><span class="line">3. 使用multiline.pattern来合并多行日志</span><br><span class="line">    老生常谈的问题, 主要解决日志多行的问题.</span><br><span class="line"></span><br><span class="line">4. 使用output.logstash传输日志到logstash</span><br><span class="line">  # 随机获取不同的主机来传输日志, 既可以实现负载又可以实现高可用</span><br><span class="line">  # 真是完美啊, 胖客户端才是王道!!!</span><br><span class="line">  hosts: [&quot;192.168.1.101:9100&quot;, &quot;192.168.1.102:9100&quot;, &quot;192.168.1.103:9100&quot;]</span><br><span class="line">  loadbalance: true</span><br></pre></td></tr></table></figure><h2 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h2><p>先来看看配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 多少个干活的</span><br><span class="line"># 进程相当于产品经理, worker相当于程序员的数量</span><br><span class="line">pipeline.workers: 8</span><br><span class="line"></span><br><span class="line"># 一次处理一批, 效率高啊</span><br><span class="line"># 就像每次吃瓜子都是抓一把</span><br><span class="line">pipeline.batch.size: 10000</span><br><span class="line"></span><br><span class="line"># 收到的数据先写入磁盘</span><br><span class="line"># 不然进程崩了, 系统挂了, 数据就丢失了</span><br><span class="line">queue.type: persisted</span><br><span class="line">path.queue: /usr/share/logstash/queue</span><br><span class="line"></span><br><span class="line"># 以文件的形式存储, 一个文件的大小</span><br><span class="line">queue.page_capacity: 256mb</span><br><span class="line"></span><br><span class="line"># 不限制最大事件数</span><br><span class="line">queue.max_events: 0</span><br><span class="line"></span><br><span class="line"># 限制最大使用80G硬盘</span><br><span class="line"># 别问为什么, 问就是不知道.</span><br><span class="line"># 猜测可能是为了避免出了问题没人发现吧.</span><br><span class="line">queue.max_bytes: 81960mb</span><br></pre></td></tr></table></figure><p>然后是logstash的pipeline<br>这里举一小段例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 匹配服务端超时的日志</span><br><span class="line">if &quot;Cost Time Too Long&quot; in [message] &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; [</span><br><span class="line">                &quot;^.*\[%&#123;TIMESTAMP_ISO8601:timestamp&#125;\].+Cost Time Too Long (?&lt;message_name&gt;\w+) (?&lt;elapsed_time&gt;[0-9.]+) (?&lt;online_time&gt;[0-9]*).*&quot;,</span><br><span class="line">                &quot;^.*\[%&#123;TIMESTAMP_ISO8601:timestamp&#125;\].+Cost Time Too Long (?&lt;message_name&gt;\w+) (?&lt;elapsed_time&gt;[0-9.]+).*&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">        add_tag =&gt; [&quot;TIMEOUT&quot;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 匹配服务端用户登录的日志</span><br><span class="line">&#125; else if &quot;Player:Login&quot; in [message] &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; [</span><br><span class="line">                &quot;^.*\[%&#123;TIMESTAMP_ISO8601:timestamp&#125;\].+Player:Login \w+ \w+ (?&lt;user_id&gt;[^ ]+).*&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">        add_tag =&gt; [&quot;LOGIN&quot;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 匹配服务端所有错误的日志</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; [</span><br><span class="line">                &quot;^.*\[%&#123;TIMESTAMP_ISO8601:timestamp&#125;\].*?stack traceback:.*?/(?&lt;fileline&gt;[^/]*.lua:[0-9]+):.*$&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">        add_tag =&gt; [&quot;ERROR&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为我们的日志格式都是非标准的, 日志等级也是很随便的<br>这就需要我们针对每个项目的格式进行转换和处理<br>以保证最终的格式都是一致的(制定了标准也很难推进)</p><h2 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h2><p>配置就不说了, 都是标配<br>主要注意的是分片和index名字的管理</p><ol><li>主分片为节点数(最高写入)</li><li>副本数为1(数据不丢)</li><li>同一个主分片和副本不能在一台机器上, 不然机器挂了就完了</li><li><p>单个分片的大小在内存大小左右就行了, 毕竟是要把数据装入内存</p></li><li><p>index的名字要么使用日期的形式命名要么使用ilm来自动管理<br> 使用日期可以灵活的对某一个日期的index做处理<br> 但是需要手动删除过期的数据</p><p> 使用ilm管理就只能通过RESTAPI来进行数据处理<br> 好处是不用自己删除过期数据</p></li></ol><h2 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h2><p>主要使用的是TSVB组件和TABLE组件<br>这个TSVB组件还不错, 就是有些需求实现不了<br>可能是我学艺不精, 毕竟才用了一个月</p><p>table组件也是奇葩的很, 创建的时候就指定了index name.<br>每次都只能修改kibana的obejct也是心累啊</p><h2 id="监控检测"><a href="#监控检测" class="headerlink" title="监控检测"></a>监控检测</h2><p>前面也提到为什么我们没有使用es的watch功能<br>主要是希望能提高告警的准确性反应出问题<br>我们策略是这样的, 取一小时内的数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">当前异常比 = 当前异常数 / 当前用户数</span><br><span class="line">昨日异常比 = 昨日异常数 / 昨日用户数</span><br><span class="line"></span><br><span class="line">相差异常比 = 当前异常比 / 昨日异常比</span><br><span class="line"></span><br><span class="line">if 昨日相差异常比 &gt; 2 and 前时相差异常比</span><br><span class="line">    报警</span><br></pre></td></tr></table></figure><p>这里还可以优化一下<br>即使当前的相差比昨天的大, 也不能隔一小时报警一次.<br>违背了我们的初心, 所以升级一下策略</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">昨日相差异常比 = 当前异常比 / 昨日异常比</span><br><span class="line">前时相差异常比 = 当前异常比 / 前时异常比</span><br><span class="line"></span><br><span class="line">if 昨日相差异常比 &gt; 2 and 前时相差异常比 &gt; 2</span><br><span class="line">    报警</span><br></pre></td></tr></table></figure><p>为什么是 &gt; 2, 这个也是拍脑袋想的<br>目前暂时没有想到更好的方法来动态调整.<br>有一个思路是根据<code>异常数的差</code>算出临界值, 只是一种思路.</p><h2 id="报警通知"><a href="#报警通知" class="headerlink" title="报警通知"></a>报警通知</h2><p>我们在DingTalk上封装了一层接口</p><ol><li>集成各种报警第三方接口</li><li>实现告警的重复收敛</li></ol><p>目前我们Crontab的时间间隔是一小时.<br>这个时间间隔目前来看可能没有太大的问题.</p><p>随着项目的发展, 可能会出现报警不及时的问题.<br>所以需要配合重复收敛功能来实现及时告警, 同时又不会重复的告警<br>完美…</p><h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>先看效果, 再谈疗程(屏蔽业务数据)</p><h2 id="统计效果"><a href="#统计效果" class="headerlink" title="统计效果"></a>统计效果</h2><p><img src="2020-05-02-15-50-03.png" alt></p><h2 id="监控效果"><a href="#监控效果" class="headerlink" title="监控效果"></a>监控效果</h2><p><img src="2020-05-02-15-44-20.png" alt></p><p>这里说说为啥会有个用户数的指标.<br>我们是这么考虑的</p><p>单纯的看日志的异常数是不准确的.<br>因为日志的异常数是随着玩家的增加而增加的.<br>很容易出现, 同样一个问题, 因为玩家增加而多次报警.<br>形成”狼来了”的感觉<br>所以这里使用用户数来做参考.</p><p>这里的用户数是登录数.<br>其实使用在线用户数效果会更好.<br>只是实现的成本较高, 以后再进行迭代.</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>首先这个系统做下来来, 用过的研发都说好.<br>毕竟研发也没有时间天天去看日志.<br>每次等用户发现BUG反馈过来, 太过于被动了.</p><p>其次, 通过聚合统计能够发现影响重大的在哪, 集中发力</p><p>当然也有一些问题存在</p><ol><li><p>目前无法快速的接入项目<br> 运维标准化和日志标准化的问题<br> 每个项目可能会有不同的监控需求</p></li><li><p>只监控了错误日志, 用户请求的超时并没有监控.<br> 研发已经没有精力做体验上的优化了, 卡个几秒大家觉得可以接受了.</p></li><li><p>异常信息挖掘<br> 集合其他主机监控, 服务指标, 业务指标来从多维度来快速定位问题.</p></li><li><p>只能发现问题, 没法解决问题<br> 如果产品初期管理不善, 那积累起来的历史问题会完全无从下手</p></li></ol><p>以上</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;我们是一家H5的游戏公司&lt;br&gt;多数项目的服务端使用SKYNET+LUA的形式开发&lt;br&gt;协议层走的的websocket&lt;/p&gt;
&lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;一般情况下我们都是走这样的流程&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1. 业务更新版本&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2. 等待用户反馈问题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3. 判断客户端还是服务端&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4. 根据用户信息查看日志&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5. 修复BUG更新版本&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;解决问题被动而且效率低下.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;大量体验不好的用户直接流失.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Ops" scheme="https://zhiwei.show/categories/Ops/"/>
    
      <category term="监控" scheme="https://zhiwei.show/categories/Ops/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="业务监控" scheme="https://zhiwei.show/categories/Ops/%E7%9B%91%E6%8E%A7/%E4%B8%9A%E5%8A%A1%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="Ops" scheme="https://zhiwei.show/tags/Ops/"/>
    
      <category term="监控" scheme="https://zhiwei.show/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="ELK" scheme="https://zhiwei.show/tags/ELK/"/>
    
      <category term="FileBeat" scheme="https://zhiwei.show/tags/FileBeat/"/>
    
  </entry>
  
  <entry>
    <title>珠海金山办公运维开发面试复盘</title>
    <link href="https://zhiwei.show/2020/05/01/%E5%A4%8D%E7%9B%98/%E9%9D%A2%E8%AF%95/%E7%8F%A0%E6%B5%B7%E9%87%91%E5%B1%B1%E5%8A%9E%E5%85%AC%E8%BF%90%E7%BB%B4%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/"/>
    <id>https://zhiwei.show/2020/05/01/复盘/面试/珠海金山办公运维开发面试复盘/</id>
    <published>2020-05-01T02:23:59.000Z</published>
    <updated>2020-05-05T08:56:40.957Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>学历: 大专</p><p>经验: 7, 8年的游戏运维</p><p>岗位: 运维开发</p><p>地点: 珠海办公</p><h1 id="前传"><a href="#前传" class="headerlink" title="前传"></a>前传</h1><h2 id="电面1"><a href="#电面1" class="headerlink" title="电面1"></a>电面1</h2><h3 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h3><p>balabala~~~</p><h3 id="对K8S的了解"><a href="#对K8S的了解" class="headerlink" title="对K8S的了解"></a>对K8S的了解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">etcd, 持久化的存储</span><br><span class="line">api-server, 组件通信的网关</span><br><span class="line">调度器, 针对资源, 亲和性的调度</span><br><span class="line">控制器, 根据状态, 策略进行变更控制</span><br><span class="line">kubelet, 负责对本地执行具体的任务</span><br><span class="line">kube-proxy, 对请求进行负载均衡</span><br><span class="line">service, pod的抽象, 对外提供统一的功能</span><br><span class="line">pod, container的抽象, 共享资源</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="OSI模型"><a href="#OSI模型" class="headerlink" title="OSI模型"></a>OSI模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">//下层为上层提供服务, 网络层以下(包括)可以不同</span><br><span class="line">//这个模型目前只是协议设计时做参考.</span><br><span class="line">应用层</span><br><span class="line">表示层</span><br><span class="line">会话层</span><br><span class="line">传输层</span><br><span class="line">网络层</span><br><span class="line">数据链路层</span><br><span class="line">物理层</span><br><span class="line"></span><br><span class="line">//目前主流使用的是基于TCP/IP的五层模型</span><br><span class="line">//因为会话层和表示层根据业务的需求不同很难达成标准</span><br><span class="line">//所以都在应用层自定义了</span><br><span class="line">应用层</span><br><span class="line">传输层</span><br><span class="line">网络层</span><br><span class="line">数据链路层</span><br><span class="line">物理层</span><br></pre></td></tr></table></figure><h3 id="vxlan的原理"><a href="#vxlan的原理" class="headerlink" title="vxlan的原理"></a>vxlan的原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将二层的数据通过UDP端口封装成三层的网络进行转发</span><br><span class="line">可以避免二层网络规模和区域的限制</span><br></pre></td></tr></table></figure><h3 id="docker的原理"><a href="#docker的原理" class="headerlink" title="docker的原理"></a>docker的原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">请求系统调用时传递参数, 从而实现多维度的隔离</span><br><span class="line">使用联合文件, COW(写时复制)降低IO实现container的文件系统</span><br><span class="line">使用cgroup限制container的资源避免引起雪崩</span><br><span class="line">使用网桥, peer实现container的网络</span><br></pre></td></tr></table></figure><h3 id="ELK的索引管理和优化"><a href="#ELK的索引管理和优化" class="headerlink" title="ELK的索引管理和优化"></a>ELK的索引管理和优化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">索引管理</span><br><span class="line">    7.0之前都是根据日期来设置index的名字, 方便清理</span><br><span class="line">    7.0之后通过ilm方式自动管理index的生命周期</span><br><span class="line"></span><br><span class="line">优化思路</span><br><span class="line">    每个分配适当的索引大小(参考内存大小)</span><br><span class="line">    调整分片数量</span><br><span class="line">    提高段合并时间</span><br><span class="line">    降低写入数据的实时性</span><br></pre></td></tr></table></figure><h2 id="电面2"><a href="#电面2" class="headerlink" title="电面2"></a>电面2</h2><h3 id="自我介绍-1"><a href="#自我介绍-1" class="headerlink" title="自我介绍"></a>自我介绍</h3><p>balabala~~</p><h3 id="七层-四层负载均衡区别以及LVS的了解"><a href="#七层-四层负载均衡区别以及LVS的了解" class="headerlink" title="七层/四层负载均衡区别以及LVS的了解"></a>七层/四层负载均衡区别以及LVS的了解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">四层的代理无法获取七层的信息</span><br><span class="line"></span><br><span class="line">client -&gt; directory -&gt; realserver</span><br><span class="line"></span><br><span class="line">1. nat</span><br><span class="line">    1.1 修改请求数据包的目标IP/目标PORT</span><br><span class="line">    1.2 将realserver的网关指向directory</span><br><span class="line">    1.3 directory收到后回复的数据包时会根据之前的nat记录还原发送给client</span><br><span class="line">2. dr</span><br><span class="line">    2.1 修改请求数据包的目标MAC地址</span><br><span class="line">    2.2 在realserver上的lo接口添加一个vip(禁止arp响应, 使用源IP发送)</span><br><span class="line">    2.3 当回复数据时, 发送给网关然后直接发送给client</span><br><span class="line">3. fullnet</span><br><span class="line">    类似于nat模式, 不只是修改目标IP和端口, 同时也会修改源IP和端口</span><br><span class="line">    这样readlserver就不需要做任何修改</span><br><span class="line">4. iptunnl</span><br><span class="line">    将收到的数据包再次封装成一个三层IP数据包, 然后发送出去</span><br><span class="line">    通过三层的网络(跨局域网), 到达realserver后解开封装的数据包获得</span><br><span class="line">    client请求的数据包, 然后处理</span><br><span class="line"></span><br><span class="line">(</span><br><span class="line">    目前不太确定iptunnl是直接回复client还是通过directory回复的, 理论上来说</span><br><span class="line">    realserver有client的请求数据包, 有iptunnl的封装包, 完全可以直接返回</span><br><span class="line">    是否有其他的问题和考虑</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="kafka吞吐量高的原因"><a href="#kafka吞吐量高的原因" class="headerlink" title="kafka吞吐量高的原因"></a>kafka吞吐量高的原因</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">每个topic会将数据拆分在不同的分区上, 而这些分区会存放在不同的broken上</span><br><span class="line">所以能够将数据处理分布在各个broken上执行, 从而实现了高吞吐量</span><br><span class="line"></span><br><span class="line">(有点类似于elasticsearch的分片机制)</span><br></pre></td></tr></table></figure><h3 id="cache-buffer"><a href="#cache-buffer" class="headerlink" title="cache/buffer"></a>cache/buffer</h3><p>cache<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">因为外部存储的操作非常耗时, 所以会尽可能的减少外部存储的操作.</span><br><span class="line"></span><br><span class="line">根据磁盘局部原理, 在读取当前数据时, 未来一段时间内, 可能会用到附近的数据</span><br><span class="line">(猜测是因为顺序写的原因)</span><br><span class="line"></span><br><span class="line">比如当我从磁盘读取数据5时, 可能会将数据4,数据6一起读取进内存(根据页大小)</span><br><span class="line">这样, 当我需要数据4时就能直接在内存里面获取了. 从而减少了外部存储的操作.</span><br><span class="line">提高了效率, 及时我不需要数据4, 我读取外部存储的耗时成本是一样.</span><br><span class="line"></span><br><span class="line">当内存不足时(进程申请的内存), 会根据LRU(最近最少使用算法)释放掉一些cache</span><br></pre></td></tr></table></figure></p><p>buffer<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">系统A发送数据时, 系统B会将收到的数据存放在buffer里面</span><br><span class="line">当系统B收到所有数据时, 将存在buffer里面的数据统一提交</span><br><span class="line">(这是因为带宽的原因, 无法将所有的数据一次发送, 只能一点点的发送)</span><br></pre></td></tr></table></figure></p><h1 id="现场面"><a href="#现场面" class="headerlink" title="现场面"></a>现场面</h1><p>上来两个面试官.</p><h2 id="面试官1"><a href="#面试官1" class="headerlink" title="面试官1"></a>面试官1</h2><h3 id="数组和链表的区别"><a href="#数组和链表的区别" class="headerlink" title="数组和链表的区别"></a>数组和链表的区别</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">数组是一种逻辑结构, 链表是一种存储结构, 链表对应的应该是顺序表</span><br><span class="line"></span><br><span class="line">可以使用链表/顺序表的存储结构实现数组</span><br></pre></td></tr></table></figure><h3 id="数组和链表的场景"><a href="#数组和链表的场景" class="headerlink" title="数组和链表的场景"></a>数组和链表的场景</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">数组的元素大小相同, 可以通过数组第一个元素的地址计算出数组内任意个元素的地址, 所以能够实现随机访问</span><br><span class="line">链表因为需要由前一个元素才能找到后一个元素, 所以只能通过遍历来寻找元素</span><br><span class="line"></span><br><span class="line">数组因为使用前需要声明大小, 所以在使用时会存在上限问题</span><br><span class="line">链表因为每个元素有一个指向下一个元素的指针, 所以理论上上限为内存大小</span><br><span class="line"></span><br><span class="line">数组插入元素时, 如果不是最后一个元素, 需要将元素一个个的后移, 然后插入新元素</span><br><span class="line">链表插入元素时, 只需修改前一个元素并将插入元素的指针指向下一个元素即可, 效率非常高</span><br><span class="line"></span><br><span class="line">数组适合大量的随机访问, 只追加不修改的方式</span><br><span class="line">链表适合大量的写操作和顺序遍历</span><br></pre></td></tr></table></figure><h3 id="redis的LIST结构如何实现快速查询和删除"><a href="#redis的LIST结构如何实现快速查询和删除" class="headerlink" title="redis的LIST结构如何实现快速查询和删除"></a>redis的LIST结构如何实现快速查询和删除</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不知</span><br></pre></td></tr></table></figure><h3 id="redis的sorted-set如何实现一个订单过期功能"><a href="#redis的sorted-set如何实现一个订单过期功能" class="headerlink" title="redis的sorted set如何实现一个订单过期功能"></a>redis的sorted set如何实现一个订单过期功能</h3><p>方案1<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将订单号设置为KEY, 超时时间设置为score.</span><br><span class="line">这样排序, 时间最短的在最前面, 然后使用一个线程每隔一段时间去检查一次.</span><br><span class="line">发现订单过期时修改数据库状态</span><br><span class="line"></span><br><span class="line">只是觉得这个方法很浪费时间, 大量重复没有意义的动作.</span><br><span class="line">没想到面试官说很多公司就是使用这种方式实现的.</span><br><span class="line">算是瞎猫碰到死耗子</span><br></pre></td></tr></table></figure></p><p>方案2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用redis的ttl, 当KEY过期后, 通过redis事件通知来修改数据库状态.</span><br><span class="line">参考https://redis.io/topics/notifications</span><br></pre></td></tr></table></figure></p><p>方案3<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">使用redis的ttl, 当KEY过期后, 订单删除</span><br><span class="line">同时在数据库添加一个订单过期的时间.</span><br><span class="line">这样可以通过时间范围来过滤一个未支付的订单.</span><br><span class="line"></span><br><span class="line">有个问题, 定单通常都是有状态属性的</span><br><span class="line">这样什么时候, 什么方式去更新这个状态呢</span><br><span class="line"></span><br><span class="line">我的想法应该是未支付状态, 通过过期时间来判断这个订单是否失效</span><br><span class="line">从使用角度看带来麻烦, 但是效率高, 较稳定</span><br></pre></td></tr></table></figure></p><h3 id="数据库的隔离级别-什么是不可重复度读"><a href="#数据库的隔离级别-什么是不可重复度读" class="headerlink" title="数据库的隔离级别, 什么是不可重复度读"></a>数据库的隔离级别, 什么是不可重复度读</h3><p>并发导致的问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">脏读:</span><br><span class="line">事物A修改数据, 事物B读取数据, 事物A回滚数据, 事物B读取的数据是错的</span><br><span class="line"></span><br><span class="line">不可重复读:</span><br><span class="line">事物A读取数据, 事物B修改数据, 事物A又读取数据, 发现数据和第一个读到的不一样</span><br><span class="line"></span><br><span class="line">幻读:</span><br><span class="line">事物A过滤数据, 事物B插入/删除数据, 事物A发现遗漏了数据</span><br><span class="line">(幻读和不可重复读的区别在于, 修改和插入/删除)</span><br></pre></td></tr></table></figure><p>事物隔离级别:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">读未提交, 接受脏读, 不可重复读, 幻读, 高效率, 低安全</span><br><span class="line">读已提交, 接受不可重读读, 幻读</span><br><span class="line">可重复读, 接受幻读, 默认</span><br><span class="line">串行化, 所有事物依次执行, 低效率, 高安全</span><br></pre></td></tr></table></figure></p><p>不可重复度实现:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">其实不清楚, 做个大胆的假设, 当事务修改数据时, COPY一个副本, 避免修改原始数据</span><br><span class="line">面试官回答差不多, 使用的是数据版本控制</span><br></pre></td></tr></table></figure></p><h3 id="一个二叉树的遍历思路"><a href="#一个二叉树的遍历思路" class="headerlink" title="一个二叉树的遍历思路"></a>一个二叉树的遍历思路</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">      A</span><br><span class="line">   B      C</span><br><span class="line">D    E  F   G</span><br></pre></td></tr></table></figure><p>要求输出ABCDEFG</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不知</span><br></pre></td></tr></table></figure><h2 id="面试官2"><a href="#面试官2" class="headerlink" title="面试官2"></a>面试官2</h2><h3 id="redis的雪崩和穿透以及预防手段"><a href="#redis的雪崩和穿透以及预防手段" class="headerlink" title="redis的雪崩和穿透以及预防手段"></a>redis的雪崩和穿透以及预防手段</h3><p>穿透<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis作为缓存是为了分担mysql的压力, 如果用户访问了大量没有缓存到的数据.</span><br><span class="line"></span><br><span class="line">请求会直接跑到mysql层, 导致应用响应很慢.</span><br><span class="line"></span><br><span class="line">在应用层做判断, 使用布隆过滤器</span><br></pre></td></tr></table></figure></p><p>击穿<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当key过期时, 大量的并发请求会瞬间压垮数据库</span><br><span class="line"></span><br><span class="line">使用互斥锁/队列来避免突发大量读数据库的请求</span><br></pre></td></tr></table></figure></p><p>雪崩<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">当一批key的ttl时间过期, 会导致redis的缓存大量的失效</span><br><span class="line"></span><br><span class="line">请求全部跑到mysql上, 结果就是应用响应慢.</span><br><span class="line"></span><br><span class="line">1. 将key的ttl设置为不同的时间, 或者不设置ttl时间(为啥要设置, 使用LRU不好吗)</span><br><span class="line">2. 当一个缓存过期时请求二级缓存, 一级缓存的时间短, 二级缓存时间长</span><br></pre></td></tr></table></figure></p><h3 id="lvs的三种模式"><a href="#lvs的三种模式" class="headerlink" title="lvs的三种模式"></a>lvs的三种模式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上同...</span><br></pre></td></tr></table></figure><h3 id="k8s的架构"><a href="#k8s的架构" class="headerlink" title="k8s的架构"></a>k8s的架构</h3><p><img src="2020-05-01-16-25-21.png" alt></p><p><img src="2020-05-01-16-25-31.png" alt></p><p><img src="2020-05-01-16-28-16.png" alt></p><p><img src="2020-05-01-17-31-41.png" alt></p><p><img src="2020-05-01-17-37-18.png" alt></p><h3 id="mysql的架构"><a href="#mysql的架构" class="headerlink" title="mysql的架构"></a>mysql的架构</h3><p><img src="2020-05-01-16-24-13.png" alt></p><h3 id="openresty请求的生命周期"><a href="#openresty请求的生命周期" class="headerlink" title="openresty请求的生命周期"></a>openresty请求的生命周期</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不知</span><br></pre></td></tr></table></figure><h3 id="写一个最大公约数-冒泡排序"><a href="#写一个最大公约数-冒泡排序" class="headerlink" title="写一个最大公约数/冒泡排序"></a>写一个最大公约数/冒泡排序</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不知</span><br></pre></td></tr></table></figure><h3 id="七层负载均衡和四层负载均衡区别"><a href="#七层负载均衡和四层负载均衡区别" class="headerlink" title="七层负载均衡和四层负载均衡区别"></a>七层负载均衡和四层负载均衡区别</h3><p><img src="四七层代理时序图.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">七层代理因为需要将数据包提交给应用层, 所以效率会慢.</span><br><span class="line">并且七层代理能根据请求的信息进行相应策略.</span><br><span class="line"></span><br><span class="line">面试官让我画出七层代理和四层代理在TCP的时序图.</span><br><span class="line">讲了七层代理, 需要先和nginx建立连接, 然后nginx再和后端建立连接.</span><br><span class="line">后来想想哦, 这里client先和nginx建立连接没问题.</span><br><span class="line"></span><br><span class="line">但不是client和nginx建立连接后, nginx立马和后端建立连接</span><br><span class="line">而是client发出了七层的请求, 然后nginx根据七层的数据进行判断和哪个后台建立连接的.</span><br><span class="line"></span><br><span class="line">而四层负载均衡是居于tcp的数据包的转发, 直接修改数据包, 效率会高出很多.</span><br></pre></td></tr></table></figure><h1 id="总结-吐槽"><a href="#总结-吐槽" class="headerlink" title="总结/吐槽"></a>总结/吐槽</h1><h3 id="从面试者的角度看"><a href="#从面试者的角度看" class="headerlink" title="从面试者的角度看"></a>从面试者的角度看</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">面完之后心里也有低了, 凉凉.</span><br><span class="line"></span><br><span class="line">HR小姐姐直接让我回了, 送都不送一下(世风日下, 人走茶凉), </span><br><span class="line">(小姐姐后来特意和我解释了, 因为正在打电话, 不想让我久等)</span><br><span class="line"></span><br><span class="line">主要问题还是积累不够吧, 工作场景的不同, 无法深入研究, 这个无解.</span><br><span class="line">但是数据结构这种通用和基础性的原理的还可以深入学习一下</span><br><span class="line"></span><br><span class="line">结束时, 问了一下面试官有什么建议吗.</span><br><span class="line">回答, 可以看看源码, 感觉有点敷衍...</span><br></pre></td></tr></table></figure><h3 id="从面试官的角度看"><a href="#从面试官的角度看" class="headerlink" title="从面试官的角度看"></a>从面试官的角度看</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">反正面试没过, 我肯定是不开心的, 坐车4小时, 来回8小时, 心累啊(可能存在不客观)</span><br><span class="line"></span><br><span class="line">面试过程中, 感觉没有问之前工作中做过什么, 达到了什么效果.</span><br><span class="line">(白白的准备了一堆的资料)</span><br><span class="line"></span><br><span class="line">整个面试过程就是, 大概就是你知道这个吗, 这个原理是什么</span><br><span class="line">完全是一问一答的方式, 不过也OK了, 目前主流的都是这样调调.</span><br><span class="line">(YY一下, 如果多背一些面试题, 是不是会更容易通过面试)</span><br><span class="line"></span><br><span class="line">而且良心的说, **两个面试官都挺不错**, 有时你回答不来, 也会给一些提示.</span><br><span class="line">但是相对来说, 我觉得第一个面试官感觉更好一些.</span><br><span class="line">因为我在和第一个面试官沟通的时候, 我们是有来有回的.</span><br><span class="line">我回答完问题后, 他会给出一些反馈.</span><br><span class="line"></span><br><span class="line">而第二个面试官整个过程就面无表情, 完全没有交互</span><br><span class="line">是对我的长相有意见(我可是有戴口罩的啊???)</span><br></pre></td></tr></table></figure><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">这是第二次面金山了, 又GET到了新知识.</span><br><span class="line">虽然没有完成大目标, 但也有一些小收获.</span><br><span class="line"></span><br><span class="line">还记得第一次在一个月黑风高的晚上.</span><br><span class="line">当时电面, 金山的面试官问了两个问题.</span><br><span class="line">shell的数组(不知道, shell还用数组???) </span><br><span class="line">单例模式(不知道, 还没看到单例模式)</span><br><span class="line"></span><br><span class="line">然后就没有然后了, 相比第一次, 应该有了很大的进步.</span><br><span class="line">再积累积累, 下次再来, 加油!</span><br></pre></td></tr></table></figure><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">在和HR小姐姐的沟通下, 获得了一些面试的反馈.</span><br><span class="line">这里我要认真的表扬下, 是真的很感谢.</span><br><span class="line"></span><br><span class="line">以下是反馈信息:</span><br><span class="line"></span><br><span class="line">如果把运维分为下面几个阶段, 我目前还处于Ops到DevOps的过渡阶段</span><br><span class="line">Ops =&gt; DevOps =&gt; DataOps =&gt; SRE =&gt; AIOps</span><br><span class="line">       ^</span><br><span class="line"></span><br><span class="line">有以下建议：</span><br><span class="line">1. 运维不能只是会简单部署, 还要深入理解组件原理, 这样才能快速处理问题或者避免问题。</span><br><span class="line">2. DevOps方法论, 开发驱动运维, 不能局限于会简单的写python层面</span><br><span class="line">   深度上需要深刻的掌握一门域名, 广度上需要熟悉golang、lua、rust等更多语言。</span><br><span class="line"></span><br><span class="line">3. 培养亿级流量思维, 集群化、高可用, CAP原理这些在分布式系统里头都是需要深入考虑的。</span><br><span class="line">4. 基于Mikey金字塔构建运维体系, 监控是基础, 没有监控, 可靠运维就是空谈, 要从底层向上构建, 打牢基础。</span><br><span class="line"></span><br><span class="line">推荐书籍：</span><br><span class="line">1. 「SRE: Google 运维解密」</span><br><span class="line">2. 「SRE生存指南」</span><br><span class="line">3. 「亿级流量网站架构核心技术」</span><br><span class="line">4. 「MySQL运维内参」</span><br><span class="line">5. 「MySQL技术内幕」</span><br><span class="line">6. 「Kubernetes权威指南」</span><br><span class="line">7. 「Redis设计与实现」</span><br><span class="line">8. 「深入理解Nginx」</span><br><span class="line">9. 「OpenStack设计与实现」</span><br><span class="line">10.  ......</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">虚心的接受建议</span><br><span class="line">但是这个运维阶段有点不同的看法</span><br><span class="line"></span><br><span class="line">devops是目的, sre/dataops/aiops都是手段</span><br><span class="line">devops的思想是快速,高质量的交付产品给用户.</span><br><span class="line">sre只是devops中运营的一环, dataops/aiops是帮助团队提交效率和稳定的方法</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;学历: 大专&lt;/p&gt;
&lt;p&gt;经验: 7, 8年的游戏运维&lt;/p&gt;
&lt;p&gt;岗位: 运维开发&lt;/p&gt;
&lt;p&gt;地点: 珠海办公&lt;/p&gt;
&lt;h1 id=&quot;前传&quot;&gt;&lt;a href=&quot;#前传&quot; class=&quot;headerlink&quot; title=&quot;前传&quot;&gt;&lt;/a&gt;前传&lt;/h1&gt;&lt;h2 id=&quot;电面1&quot;&gt;&lt;a href=&quot;#电面1&quot; class=&quot;headerlink&quot; title=&quot;电面1&quot;&gt;&lt;/a&gt;电面1&lt;/h2&gt;&lt;h3 id=&quot;自我介绍&quot;&gt;&lt;a href=&quot;#自我介绍&quot; class=&quot;headerlink&quot; title=&quot;自我介绍&quot;&gt;&lt;/a&gt;自我介绍&lt;/h3&gt;&lt;p&gt;balabala~~~&lt;/p&gt;
&lt;h3 id=&quot;对K8S的了解&quot;&gt;&lt;a href=&quot;#对K8S的了解&quot; class=&quot;headerlink&quot; title=&quot;对K8S的了解&quot;&gt;&lt;/a&gt;对K8S的了解&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;etcd, 持久化的存储&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;api-server, 组件通信的网关&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;调度器, 针对资源, 亲和性的调度&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;控制器, 根据状态, 策略进行变更控制&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kubelet, 负责对本地执行具体的任务&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;kube-proxy, 对请求进行负载均衡&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;service, pod的抽象, 对外提供统一的功能&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pod, container的抽象, 共享资源&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="复盘" scheme="https://zhiwei.show/categories/%E5%A4%8D%E7%9B%98/"/>
    
      <category term="面试" scheme="https://zhiwei.show/categories/%E5%A4%8D%E7%9B%98/%E9%9D%A2%E8%AF%95/"/>
    
    
      <category term="面试" scheme="https://zhiwei.show/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="运维开发" scheme="https://zhiwei.show/tags/%E8%BF%90%E7%BB%B4%E5%BC%80%E5%8F%91/"/>
    
      <category term="复盘" scheme="https://zhiwei.show/tags/%E5%A4%8D%E7%9B%98/"/>
    
  </entry>
  
</feed>
